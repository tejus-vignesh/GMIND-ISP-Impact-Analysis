#!/usr/bin/env python3
"""
Filter ground truth and predictions to include only moving objects.

Identifies moving objects by detecting objects that appear in multiple
consecutive frames. This is useful for evaluating detection performance
specifically on moving objects, which are often more challenging to detect
than static objects.

Moving Object Detection:
    An object is considered "moving" if it appears in at least N frames
    (default: 3) with the same track_id. This uses the track_id field
    from annotations generated by the annotation pipeline, which is more
    accurate than IoU-based matching.

Output:
    Creates filtered versions of GT and results files:
    - coco_gt_moving.json: GT annotations for moving objects only
    - coco_results_moving.json: Predictions matched to moving GT objects

Usage:
    python -m Evaluation.utils.filter_moving_objects \\
        --gt-file baseline_evaluation_results/coco_gt.json \\
        --results baseline_evaluation_results/coco_results.json \\
        --output-dir baseline_evaluation_results \\
        --min-consecutive-frames 3
"""

import argparse
import json
import sys
from collections import defaultdict
from pathlib import Path

import numpy as np

sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from pycocotools.coco import COCO

from Evaluation.core.baseline_detector_and_tracker import (
    create_coco_gt_from_dataset,
    get_gmind_dataloader,
    load_config,
)


def compute_iou(box1, box2):
    """
    Compute IoU between two boxes in [x, y, w, h] format.

    This is still used for matching predictions to ground truth annotations
    when filtering results, but track IDs are used for identifying moving objects.
    """
    x1_1, y1_1, w1, h1 = box1
    x2_1, y2_1 = x1_1 + w1, y1_1 + h1

    x1_2, y1_2, w2, h2 = box2
    x2_2, y2_2 = x1_2 + w2, y1_2 + h2

    # Intersection
    x1_i = max(x1_1, x1_2)
    y1_i = max(y1_1, y1_2)
    x2_i = min(x2_1, x2_2)
    y2_i = min(y2_1, y2_2)

    if x2_i <= x1_i or y2_i <= y1_i:
        return 0.0

    intersection = (x2_i - x1_i) * (y2_i - y1_i)
    area1 = w1 * h1
    area2 = w2 * h2
    union = area1 + area2 - intersection

    if union == 0:
        return 0.0

    return intersection / union


def identify_moving_objects_from_tracking(coco_gt, coco_results, min_frames=3, iou_threshold=0.3):
    """
    Identify moving objects using track IDs from annotations.

    Objects that appear in at least min_frames frames (with the same track_id)
    are considered moving. This uses the track_id field that should be present
    in annotations generated by the annotation pipeline.

    Algorithm:
        1. Group annotations by track_id
        2. Count how many frames each track appears in
        3. Tracks appearing in >= min_frames are considered moving
        4. All annotations with those track_ids are marked as moving

    Args:
        coco_gt: COCO ground truth object
        coco_results: List of prediction results (not used but kept for API consistency)
        min_frames: Minimum number of frames an object must appear in
                   to be considered moving (default: 3)
        iou_threshold: Not used when track_id is available, kept for API compatibility

    Returns:
        Set of GT annotation IDs that are identified as moving objects
    """
    print(f"\nIdentifying moving objects using track IDs (appearing in >= {min_frames} frames)...")

    # Group annotations by track_id
    tracks_by_id = defaultdict(list)  # track_id -> list of (image_id, ann_id)
    annotations_without_track_id = []

    for ann in coco_gt.anns.values():
        track_id = ann.get("track_id")
        if track_id is not None:
            tracks_by_id[track_id].append((ann["image_id"], ann["id"]))
        else:
            annotations_without_track_id.append(ann["id"])

    if annotations_without_track_id:
        print(f"  Warning: {len(annotations_without_track_id)} annotations missing track_id field.")
        print("  These will be excluded from moving object identification.")

    # Count frames per track (unique image_ids per track)
    track_frame_counts = {}
    for track_id, ann_list in tracks_by_id.items():
        unique_frames = len(set(img_id for img_id, _ in ann_list))
        track_frame_counts[track_id] = unique_frames

    # Identify moving tracks: those appearing in >= min_frames
    moving_track_ids = {
        track_id
        for track_id, frame_count in track_frame_counts.items()
        if frame_count >= min_frames
    }

    # Collect all annotation IDs from moving tracks
    moving_ann_ids = set()
    for track_id in moving_track_ids:
        for img_id, ann_id in tracks_by_id[track_id]:
            moving_ann_ids.add(ann_id)

    print(f"Found {len(moving_track_ids)} moving tracks (out of {len(tracks_by_id)} total tracks)")
    print(f"Found {len(moving_ann_ids)} moving GT annotations (out of {len(coco_gt.anns)})")
    if len(coco_gt.anns) > 0:
        print(f"  {100*len(moving_ann_ids)/len(coco_gt.anns):.1f}% of GT objects are moving")

    return moving_ann_ids


def filter_coco_gt(coco_gt, moving_ann_ids, output_path):
    """Filter COCO GT to only include moving objects"""
    # Create new COCO data structure
    new_images = []
    new_annotations = []
    new_categories = coco_gt.loadCats(coco_gt.getCatIds())

    # Keep all images (we'll filter annotations)
    for img_id, img_info in coco_gt.imgs.items():
        new_images.append(
            {
                "id": img_id,
                "width": img_info["width"],
                "height": img_info["height"],
                "file_name": img_info.get("file_name", f"frame_{img_id:06d}.jpg"),
            }
        )

    # Keep only moving annotations
    ann_id = 1
    for ann_id_old, ann in coco_gt.anns.items():
        if ann_id_old in moving_ann_ids:
            new_ann = ann.copy()
            new_ann["id"] = ann_id
            new_annotations.append(new_ann)
            ann_id += 1

    new_coco_data = {
        "info": coco_gt.dataset.get("info", {}),
        "licenses": coco_gt.dataset.get("licenses", []),
        "images": new_images,
        "annotations": new_annotations,
        "categories": new_categories,
    }

    with open(output_path, "w") as f:
        json.dump(new_coco_data, f, indent=2)

    print(f"\nSaved filtered GT to: {output_path}")
    print(f"  Original annotations: {len(coco_gt.anns)}")
    print(f"  Moving annotations: {len(new_annotations)}")
    print(f"  Reduction: {100*(1 - len(new_annotations)/len(coco_gt.anns)):.1f}%")

    return new_coco_data


def filter_coco_results(coco_results, coco_gt, moving_ann_ids, output_path):
    """Filter COCO results to only include predictions that match moving GT objects"""
    # Group GT by image_id
    gt_by_image = defaultdict(list)
    for ann in coco_gt.anns.values():
        if ann["id"] in moving_ann_ids:
            gt_by_image[ann["image_id"]].append(ann)

    # Match predictions to moving GT
    filtered_results = []
    matched_count = 0

    results_by_image = defaultdict(list)
    for result in coco_results:
        results_by_image[result["image_id"]].append(result)

    for img_id in sorted(results_by_image.keys()):
        pred_results = results_by_image[img_id]
        moving_gt = gt_by_image.get(img_id, [])

        for pred in pred_results:
            pred_bbox = pred["bbox"]
            pred_cat_id = pred["category_id"]

            # Check if this prediction matches any moving GT object
            for gt_ann in moving_gt:
                if gt_ann["category_id"] != pred_cat_id:
                    continue

                iou = compute_iou(pred_bbox, gt_ann["bbox"])
                if iou >= 0.5:  # Match threshold
                    filtered_results.append(pred)
                    matched_count += 1
                    break

    with open(output_path, "w") as f:
        json.dump(filtered_results, f, indent=2)

    print(f"\nSaved filtered results to: {output_path}")
    print(f"  Original predictions: {len(coco_results)}")
    print(f"  Predictions matching moving GT: {len(filtered_results)}")
    print(f"  Reduction: {100*(1 - len(filtered_results)/len(coco_results)):.1f}%")

    return filtered_results


def main():
    parser = argparse.ArgumentParser(description="Filter GT and predictions to only moving objects")
    parser.add_argument("--gt-file", type=str, required=True, help="Path to COCO GT JSON file")
    parser.add_argument("--results", type=str, required=True, help="Path to COCO results JSON file")
    parser.add_argument(
        "--output-dir", type=str, default="baseline_evaluation_results", help="Output directory"
    )
    parser.add_argument(
        "--min-frames",
        type=int,
        default=3,
        help="Minimum number of consecutive frames an object must appear in to be considered moving (default: 3)",
    )
    parser.add_argument(
        "--iou-threshold",
        type=float,
        default=0.3,
        help="IoU threshold for matching predictions to GT (not used for track identification, kept for compatibility)",
    )
    args = parser.parse_args()

    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Load GT
    gt_path = Path(args.gt_file)
    if not gt_path.exists():
        gt_path = output_dir / gt_path.name

    print(f"Loading GT from: {gt_path}")
    coco_gt = COCO(str(gt_path))

    # Load results
    results_path = Path(args.results)
    if not results_path.exists():
        results_path = output_dir / results_path.name

    print(f"Loading results from: {results_path}")
    with open(results_path, "r") as f:
        coco_results = json.load(f)

    # Identify moving objects
    moving_ann_ids = identify_moving_objects_from_tracking(
        coco_gt, coco_results, min_frames=args.min_frames, iou_threshold=args.iou_threshold
    )

    # Filter GT
    filtered_gt_path = output_dir / "coco_gt_moving.json"
    filter_coco_gt(coco_gt, moving_ann_ids, filtered_gt_path)

    # Filter results
    filtered_results_path = output_dir / "coco_results_moving.json"
    filter_coco_results(coco_results, coco_gt, moving_ann_ids, filtered_results_path)

    print("\n" + "=" * 70)
    print("Filtering complete!")
    print("=" * 70)
    print(f"Filtered GT: {filtered_gt_path}")
    print(f"Filtered results: {filtered_results_path}")
    print(f"\nTo evaluate with moving objects only, run:")
    print(f"  python -m Evaluation.core.baseline_detector_and_tracker \\")
    print(f"    --load-results {filtered_results_path} \\")
    print(f"    --gt-file {filtered_gt_path} \\")
    print(f"    --output-dir {output_dir}")


if __name__ == "__main__":
    main()
